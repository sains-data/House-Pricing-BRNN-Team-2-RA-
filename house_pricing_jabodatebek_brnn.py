# -*- coding: utf-8 -*-
"""House Pricing Jabodatebek_BRNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BvEtk65C6XnfflBTOiS3PO6_R1yVPxet

# **2. INTRODUCTION**

# **1. "Revolutionize banking with cutting-edge Machine Learning: House Price Prediction, empowering banks to make smarter lending decisions and mitigate risks effectively."**

"Dalam era modern ini, ketika teknologi semakin merambah berbagai aspek kehidupan, industri perbankan juga semakin menggabungkan inovasi teknologi untuk mengoptimalkan layanan dan pengambilan keputusan. Penelitian yang saya lakukan, berfokus pada prediksi harga rumah dengan menggunakan teknik Machine Learning. Penelitian ini memiliki tujuan : memberikan dunia perbankan opsi yang kuat untuk mengantisipasi dan mengelola risiko kredit serta mengoptimalkan pengambilan keputusan dalam penilaian aset properti. Lalu Bank juga dapat menggunakan hasil prediksi ini untuk menilai kelayakan pinjaman hipotek dengan lebih tepat, mengidentifikasi potensi risiko kredit, dan merencanakan strategi investasi yang lebih cerdas.

Dalam pandangan lebih luas, penelitian ini bukan hanya tentang memprediksi harga rumah semata, tetapi juga tentang memberikan solusi yang inovatif bagi dunia perbankan dalam menghadapi tantangan kompleks. Melalui penggabungan teknologi Machine Learning dengan kebijakan risiko perbankan, penelitian ini membuka peluang baru untuk pengambilan keputusan yang lebih akurat dan responsif. Dengan model prediksi harga rumah ini, kami berharap dapat memberikan kontribusi positif bagi efisiensi operasional bank serta memperkuat daya saing industri dalam menghadapi dinamika pasar properti yang selalu berubah."

# **3. EXTERNAL LINK**

1. Dataset : https://www.kaggle.com/datasets/nafisbarizki/daftar-harga-rumah-jabodetabek

2. Deployment : https://huggingface.co/spaces/Dzlkrn/House_Price_Prediction

# **4. WORKING AREA**
"""



"""## **A. LIBRARIES & DATASET LOADING**"""

!pip install phik
!pip install feature_engine
!pip install dataprep

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import joblib
import phik
import imblearn

from dataprep.eda import create_report
from numpy import array
from feature_engine.outliers import Winsorizer
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer, TransformedTargetRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, r2_score, mean_squared_error, mean_absolute_error, roc_auc_score, ConfusionMatrixDisplay, confusion_matrix, classification_report
from sklearn.inspection import permutation_importance
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.feature_selection import SelectFromModel
from sklearn.base import BaseEstimator, TransformerMixin
from imblearn.over_sampling import SMOTENC
from sklearn.ensemble import RandomForestRegressor

warnings.filterwarnings(action='ignore')

# %matplotlib inline

df = pd.read_csv('/content/jabodetabek_house_price.csv')
df

"""## **B. DATA PREPROCESSING**

### B.1. DATASET OVERVIEW
"""

#info detail dari dataset
df.info()

report = create_report(df)
report
#apabila ingin melihat summary secara general bisa menggunakan sintaks diatas

"""### B.2. DATA CLEANING"""

#duplikasi dataframe
df_dc = df.copy()

#Save data bersih
file_path = 'jabodetabek_bersih.csv'
df_dc.to_csv(file_path, index=False)

"""#### **COLUMNS HANDLING**

##### **HANDLING DATA YANG TIDAK SESUAI**

**1. Kolom 'price_in_rp'**

Peneliti melakukan pengecekkan terhadap kolom 'price_in_rp' dimana terdapat beberapa value harga yang dalam asumsi peneliti *typo* pada saat penulisan, oleh karena-nya peneliti melakukan penyesuaian
"""

#mencari 10 nilai terbesar pada kolom 'price_in_rp'
df_dc['price_in_rp'].nlargest(10)

#menyesuaikan value
df_dc.loc[df_dc['price_in_rp'] == 580000000000.0, 'price_in_rp'] = 58000000000.0
df_dc.loc[df_dc['price_in_rp'] == 250000000000.0, 'price_in_rp'] = 25000000000.0
df_dc.loc[df_dc['price_in_rp'] == 175000000000.0, 'price_in_rp'] = 17500000000.0
df_dc.loc[df_dc['price_in_rp'] == 150000000000.0, 'price_in_rp'] = 15000000000.0
df_dc.loc[df_dc['price_in_rp'] == 110000000000.0, 'price_in_rp'] = 11000000000.0
df_dc.loc[df_dc['price_in_rp'] == 108000000000.0, 'price_in_rp'] = 10800000000.0
df_dc.loc[df_dc['price_in_rp'] == 106000000000.0, 'price_in_rp'] = 10600000000.0
df_dc.loc[df_dc['price_in_rp'] == 100000000000.0, 'price_in_rp'] = 10000000000.0

#recek
df_dc['price_in_rp'].nlargest(10)

#recek
df_dc['carports'].nlargest(10)

"""**2. Kolom 'prorerty_type'**"""

#cek kesalahan pada kolom terkait
df.iloc[2282]

#revisi value kolom terkait
df_dc.loc[df_dc['title'].str.contains('kos|kost|Kos|Kost', case=False), 'property_type'] = 'kost'

#recek
df_dc.iloc[2282]

"""##### **DROPPING KOLOM TAK TERPAKAI**

Peneliti akan membuang beberapa kolom tidak terpakai :

1. Address, peneliti berasumsi informasi yang sama sudah tersaji di kolom lain
2. Url, peneliti berasumsi tidak memiliki kaitan dengan prediksi harga rumah
3. Title, peneliti berasumsi tidak memiliki kaitan dengan prediksi harga rumah
4. building_age, peneliti berasumsi bahwa nilainya tidak relevan dengan tahun 2023
"""

#membuang kolom tak terpakai
df_dc.drop(['address', 'url', 'title', 'building_age'], axis=1, inplace=True)

"""##### **PENYESUAIAN TIPE DATA**"""

#menghapus unit "mah" dari nilai dalam kolom
df_dc['electricity'] = df_dc['electricity'].str.replace(' mah', '')

#mengganti 'lainnya' dengan '0' pada kolom 'electricity'
df_dc['electricity'] = df_dc['electricity'].str.replace('lainnya', '0')

#mengubah jenis data kolom 'electricity' menjadi float (jika belum float)
df_dc['electricity'] = df_dc['electricity'].astype(float)

#mengubah nilai '0' dengan nilai median pada kolom 'electricity'
median_value = df_dc['electricity'].median()
df_dc['electricity'] = df_dc['electricity'].replace(0, median_value)

"""##### **DUPLICATED DATA HANDLING**"""

#pengecekkan data duplikat pada dataframe
df_dc[df_dc.duplicated()].shape

"""Tidak terdapat data duplikat

#### **EDA**

##### 1. Tipe Properti
"""

plt.figure(figsize=(6, 4))
sns.countplot(data=df_dc, x='property_type', palette='Set2')
plt.title('Jumlah Properti Berdasarkan Tipe')
plt.xlabel('Tipe Properti')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

"""Pada dataset ini terdapat dua jenis properti yakni :
1. Rumah
2. Kost
Dimana mayoritas jenis properti yang ada pada dataset ini merupakan Rumah
"""

plt.figure(figsize=(6, 4))
sns.barplot(data=df_dc, x='property_type', y='price_in_rp', ci=None, palette='Set2')
plt.title('Rata-rata Harga Properti Berdasarkan Tipe')
plt.xlabel('Tipe Properti')
plt.ylabel('Rata-rata Harga (Rp)')
plt.xticks(rotation=45)
plt.show()

"""Akan tetapi berdasarkan harganya, rata-rata harga kost pada wilayah Jabodetabek jauh lebih tinggi bahkan hampir tiga kali lipat dibandingkan dengan harga rumah.

##### 2. Kota/Kabupaten
"""

plt.subplot(1, 2, 1)
city_counts = df['city'].value_counts()
colors = plt.cm.Set2.colors
plt.pie(city_counts, labels=city_counts.index, autopct='%1.1f%%', startangle=140, colors=colors)
plt.title('Sebaran Kota')

plt.tight_layout()
plt.show()

"""Dari dataset diatas mayoritas properti yang dijual berada di wilayah Bogor."""

#urutan kota berdasarkan harga rata-rata
sorted_cities = df.groupby('city')['price_in_rp'].mean().sort_values(ascending=False).index

plt.figure(figsize=(10, 6))
sns.barplot(data=df, x='city', y='price_in_rp', estimator='mean', ci=None, order=sorted_cities, palette='Set2')
plt.title('Perbandingan Harga Rata-rata di Tiap Kota')
plt.xlabel('Kota')
plt.ylabel('Harga Rata-rata (IDR)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Berdasrkan visualisasi diatas dapat dilihat top 3 properti dengan harga rata-rata paling tinggi ada di Provinsi Jakarta.

Peneliti beranggapan hal tersebut dikarenakan karena harga tanah dan bangunan di wilayah tersebut yang sangat tinggi, namun apabila dilihat juga dari dataset, bisa saja hal tersebut dikarenakan jenis properti yang dijual pada ketiga wilayah tersebut terdapat jenis properti 'kost' yang mana harganya memang sangat tinggi.

##### Tipe Furnishing
"""

plt.figure(figsize=(8, 6))
sns.countplot(data=df, x='furnishing', palette='Set2')
plt.title('Distribusi Tipe Furnishing Properti')
plt.xlabel('Tipe Furnishing')
plt.ylabel('Jumlah Properti')
plt.xticks(rotation=45)
plt.show()

"""Pada dataset ini mayoritas tipe properti memiliki tipe unfurnished atau belum terdapat furnitur pada propertinya. Dimana berdasarkan asumsi peneliti seharusnya tipe properti seperti ini memiliki harga yang seharusnya tidak tinggi. Dan akan dibutkikan pada visualisasi dibawah."""

plt.figure(figsize=(10, 6))
average_price_by_furnishing = df.groupby('furnishing')['price_in_rp'].mean().sort_values(ascending=False)
sns.barplot(x=average_price_by_furnishing.index, y=average_price_by_furnishing.values, palette='Set2')
plt.title('Rata-rata Harga Berdasarkan Tipe Furnishing')
plt.xlabel('Tipe Furnishing')
plt.ylabel('Rata-rata Harga (Rp)')
plt.xticks(rotation=45)
plt.show()

"""Berdasarkan asumsi peneliti sebelumny terbuki bahwa tipe rumah yang *unfurnished* lebih rendah. Dan berdasarkan visualisasi diatas, dapat kita lihat bahwa rata-rata harga properti paling tinggi dimiliki oleh jenis *furnished* atau telah terdapat furnitur di dalam propertinya.

#### **FEATURES SELECTION**

Peneliti menggunakan teknik *PHIK* correlation untuk mengetahui fitur (informasi) apa yang paling berpengaruh terhadap harga rumah.
"""

#resampling
sample_size = 500
df_dc_resampled = df_dc.sample(n=sample_size, random_state=42)

#korelasi
cor_tbl = df_dc_resampled.phik_matrix()
cor_tbl.sort_values(by=['price_in_rp'], ascending=False, inplace=True)

print(cor_tbl)

#memunculkan fitur yang memiliki korelasi diatas 0,4
filtered_cor_tbl = cor_tbl.query('price_in_rp > 0.4')
print(filtered_cor_tbl)

"""Berdasarkan hasil uji korelasi diatas, peneliti hanya mengambil fitur-fitur yang memiliki skor diatas 0,5. Berdasarkan uji korelasi diatas, berikut beberapa fitur terpilih :

1. facilities
2. building_size_m2
3. district
4. electricity
5. carports
6. garages
7. city
8. land_size_m2
9. maid_bathrooms
10. maid_bedrooms
11. year_built
12. bathrooms
13. bedrooms         



"""

filtered_cor_tbl.info()

#menentukan kolom untuk target dan fitur
selected_features = ['facilities','building_size_m2', 'district', 'electricity', 'carports', 'garages', 'city', 'land_size_m2', 'maid_bathrooms', 'maid_bedrooms', 'year_built', 'bathrooms', 'bedrooms']

X = df_dc[selected_features]
y = df_dc['price_in_rp']

"""#### **CEK MISSING VALUE**"""

#hitung jumlah kolom-kolom yang memiliki missing value
missing_values = X.isnull().sum()

print(missing_values)

X.info()

"""Missing values akan di handling bersamaan dengan pembuatan *pipeline* dimana missing value pada ketiga kolom diatas akan diisi dengan nilai median.

### B.3. DATA SPLITING
"""



# Split data menjadi training dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train

"""## C. **MODELING**

### C.1. PIPELINE
"""

# Define numerical and categorical features
numerical_features = ['building_size_m2', 'electricity', 'carports', 'garages', 'land_size_m2', 'maid_bathrooms', 'maid_bedrooms', 'year_built', 'bathrooms', 'bedrooms']
categorical_features = ['facilities', 'district', 'city']

# Numerical features pipeline
numerical_pipeline = Pipeline([
    ('impute_median', SimpleImputer(strategy='median')),
    ('winsorize', Winsorizer(capping_method='iqr', tail='both', fold=1.5)),
    ('scale', StandardScaler())
])

# Categorical features pipeline
categorical_pipeline = Pipeline([
    ('impute_mode', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Full pipeline
full_pipeline = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ]
)

full_pipeline

"""### C.2. MODELING

**LSTM**
"""

!pip install tensorflow

!pip install --upgrade tensorflow

"""**BRNN**"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Bidirectional, LSTM, Dense
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score



import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Bidirectional, LSTM, Dense
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import joblib

# Persiapan Data Deret Waktu
price_sequence = df_dc['price_in_rp'].values.reshape(-1, 1)

# Normalisasi Data
scaler = StandardScaler()
price_sequence_scaled = scaler.fit_transform(price_sequence)


# Fungsi untuk membuat dataset dengan sekuens waktu
def create_sequence_dataset(dataset, time_steps=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - time_steps):
        a = dataset[i:(i + time_steps), 0]
        dataX.append(a)
        dataY.append(dataset[i + time_steps, 0])
    return np.array(dataX), np.array(dataY)

# Menentukan Hyperparameter
time_steps = 10  # Ubah sesuai kebutuhan
n_features = 1  # Satu fitur (harga rumah)

# Split data menjadi data pelatihan dan data uji
split_percentage = 0.8
split_index = int(split_percentage * len(price_sequence_scaled))

train_data = price_sequence_scaled[:split_index]
test_data = price_sequence_scaled[split_index:]

# Membuat dataset untuk BRNN
X_train, y_train = create_sequence_dataset(train_data, time_steps)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))

X_test, y_test = create_sequence_dataset(test_data, time_steps)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], n_features))

# Membuat model BRNN
model_brnn = Sequential()
model_brnn.add(Bidirectional(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], n_features))))
model_brnn.add(Bidirectional(LSTM(units=50)))
model_brnn.add(Dense(units=1))
model_brnn.compile(optimizer='adam', loss='mean_squared_error')

# Melatih model BRNN
model_brnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

joblib.dump(scaler, 'scaler.joblib')

price_sequence_scaled

# Evaluasi model BRNN pada data latih
train_predict = model_brnn.predict(X_train)
train_predict = scaler.inverse_transform(train_predict)
y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1))

# Evaluasi model BRNN pada data uji
test_predict = model_brnn.predict(X_test)
test_predict = scaler.inverse_transform(test_predict)
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluasi performa (MSE dan R^2)
train_mse = mean_squared_error(y_train_original, train_predict)
test_mse = mean_squared_error(y_test_original, test_predict)

train_r2 = r2_score(y_train_original, train_predict)
test_r2 = r2_score(y_test_original, test_predict)

print("Train Mean Squared Error (MSE):", train_mse)
print("Test Mean Squared Error (MSE):", test_mse)

print("Train R-squared (R2):", train_r2)
print("Test R-squared (R2):", test_r2)

# Plot hasil prediksi pada data uji
plt.figure(figsize=(10, 6))
plt.plot(y_test_original, label='Actual Price')
plt.plot(test_predict, label='Predicted Price')
plt.title('Actual vs Predicted Price on Test Data')
plt.xlabel('Time Steps')
plt.ylabel('Price')
plt.legend()
plt.show()

# Melatih model BRNN
model = model_brnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))

# Prediksi menggunakan model BRNN
y_train_pred = model_brnn.predict(X_train)
y_test_pred = model_brnn.predict(X_test)

# Transformasi hasil prediksi kembali ke skala asli
y_train_pred_original = scaler.inverse_transform(y_train_pred.reshape(-1, 1))
y_test_pred_original = scaler.inverse_transform(y_test_pred.reshape(-1, 1))
y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1))
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))

# Menghitung dan menampilkan MSE dan R2 score
train_mse = mean_squared_error(y_train_original, y_train_pred_original)
test_mse = mean_squared_error(y_test_original, y_test_pred_original)
train_r2 = r2_score(y_train_original, y_train_pred_original)
test_r2 = r2_score(y_test_original, y_test_pred_original)

print("Train MSE:", train_mse)
print("Test MSE:", test_mse)
print("Train R2 Score:", train_r2)
print("Test R2 Score:", test_r2)

# Visualisasi hasil prediksi
plt.figure(figsize=(12, 6))

# Plot data pelatihan
plt.subplot(1, 2, 1)
plt.plot(y_train_original, label="Actual")
plt.plot(y_train_pred_original, label="Predicted")
plt.title("Training Data - Actual vs Predicted")
plt.legend()

# Plot data uji
plt.subplot(1, 2, 2)
plt.plot(y_test_original, label="Actual")
plt.plot(y_test_pred_original, label="Predicted")
plt.title("Test Data - Actual vs Predicted")
plt.legend()

plt.show()

"""**Save Model**"""

model_brnn.save('model_brnn.h5')



"""Berdasarkan hasil *tunning* diatas, hasil yang ditunjukkan lebih stabil dari semua model. Oleh karenanya peneliti akan menggunakan based model terbaik yakni BRNN

### C.3. MODEL IMPROVEMENT

# CONCLUSIONS AND OVERALL ANALYSIS

**Conclusions:**

1. Hasil dari penelitian menunjukkan adanya indikasi overfit sebelum dan setelah dilakukan tuning. Meskipun telah dilakukan penyetelan (tuning) pada model, terlihat bahwa hasil prediksi masih menunjukkan adanya perbedaan yang signifikan antara performa pada data latih dan data uji. Oleh karena itu, untuk meningkatkan kualitas model, kami merekomendasikan untuk lebih memperhatikan teknik penanganan overfitting, seperti pengaturan parameter yang lebih sesuai dan penggunaan teknik regularisasi yang tepat.

2. Penelitian ini memberikan kontribusi yang berharga bagi pihak bank dalam operasionalnya, terutama di divisi yang berkaitan dengan penilaian aset, analisis risiko kredit, dan strategi pemasaran produk perumahan. Model prediksi harga rumah dapat membantu bank dalam melakukan penilaian cepat dan akurat terhadap harga rumah yang akan dijaminkan, memperbaiki proses pengambilan keputusan terkait kredit, serta menyediakan panduan dalam perencanaan pemasaran produk perumahan.

**Overall Analysis:**

Penelitian ini menggambarkan proses pengembangan dan penilaian model prediksi harga rumah dengan menggunakan berbagai metode regresi dan teknik pemrosesan data. Namun, hasil evaluasi menunjukkan adanya potensi overfitting pada model yang memerlukan perhatian lebih lanjut. Secara keseluruhan, penelitian ini menghadirkan peluang besar bagi pihak bank untuk meningkatkan efisiensi operasional, meningkatkan akurasi penilaian aset, dan mengoptimalkan strategi bisnis.

Dalam aplikasi dunia perbankan, model prediksi harga rumah dapat diimplementasikan dalam beberapa cara yang bermanfaat:

1. **Penilaian Kredit yang Lebih Cepat dan Akurat:** Dalam proses pengajuan kredit perumahan, bank dapat menggunakan model ini untuk mempercepat penilaian harga rumah yang diajukan sebagai jaminan. Hal ini akan membantu bank dalam mengambil keputusan kredit yang lebih cepat dan lebih akurat.

2. **Analisis Risiko Kredit yang Lebih Mendalam:** Model prediksi harga rumah dapat menjadi komponen penting dalam analisis risiko kredit. Bank dapat menggabungkan informasi prediksi harga dengan data lainnya untuk mengukur risiko yang terkait dengan nilai aset yang dijaminkan dan membantu dalam menentukan besaran kredit yang sesuai.

3. **Strategi Pemasaran Produk Perumahan:** Model ini juga dapat digunakan oleh tim pemasaran bank untuk mengidentifikasi segmen pasar potensial, merencanakan harga yang kompetitif, dan mengoptimalkan kampanye pemasaran produk perumahan.

4. **Pengembangan Portofolio Produk:** Informasi prediksi harga rumah dapat membantu bank dalam mengembangkan portofolio produk perumahan yang lebih sesuai dengan preferensi dan potensi pasar, serta mengidentifikasi peluang investasi.

Dengan mengimplementasikan model prediksi harga rumah, bank dapat meningkatkan efisiensi operasional, mengurangi risiko kredit, dan mengambil keputusan bisnis yang lebih cerdas dalam industri perbankan yang semakin kompetitif.
"""